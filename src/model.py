# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15YEBuUwPqF8Tz_rrS34iAll1kgJy4Ttr
"""

import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, GRU, Bidirectional, Conv1D, MaxPooling1D, Flatten
from tensorflow.keras.optimizers import Adam

# 游늵 H맔 캠치nh gi치 m칪 h칣nh
def evaluate_model(y_true, y_pred):
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
    return {
        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),
        'MAE': mean_absolute_error(y_true, y_pred),
        'R2': r2_score(y_true, y_pred),
        'MAPE': mape,
        'CVRMSE': np.sqrt(mean_squared_error(y_true, y_pred)) / np.mean(y_true) * 100
    }

# 游 C치c m칪 h칣nh Machine Learning
ml_models = {
    'LinearRegression': LinearRegression(),
    'KNN': KNeighborsRegressor(n_neighbors=5),
    'DecisionTree': DecisionTreeRegressor(),
    'RandomForest': RandomForestRegressor(n_estimators=100),
    'SVR_RBF': SVR(kernel='rbf')
}

# 游대 LSTM
def train_lstm_model(X_train, y_train, X_test, y_test, units=64, dropout=0.2, learning_rate=0.001, batch_size=32, epochs=50):
    model = Sequential()
    model.add(LSTM(units, input_shape=(X_train.shape[1], X_train.shape[2])))
    model.add(Dropout(dropout))
    model.add(Dense(1))
    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')
    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size, verbose=0)
    return model, history

# 游대 GRU
def train_gru_model(X_train, y_train, X_test, y_test, units=64, dropout=0.2, learning_rate=0.001, batch_size=32, epochs=50):
    model = Sequential()
    model.add(GRU(units, input_shape=(X_train.shape[1], X_train.shape[2])))
    model.add(Dropout(dropout))
    model.add(Dense(1))
    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')
    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size, verbose=0)
    return model, history

# 游대 BiLSTM
def train_bilstm_model(X_train, y_train, X_test, y_test, units=64, dropout=0.2, learning_rate=0.001, batch_size=32, epochs=50):
    model = Sequential()
    model.add(Bidirectional(LSTM(units), input_shape=(X_train.shape[1], X_train.shape[2])))
    model.add(Dropout(dropout))
    model.add(Dense(1))
    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')
    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size, verbose=0)
    return model, history

# 游 CNN
def train_cnn_model(X_train, y_train, X_test, y_test, filters=64, kernel_size=2, dropout=0.2, learning_rate=0.001, batch_size=32, epochs=50):
    model = Sequential()
    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))
    model.add(MaxPooling1D(pool_size=2))
    model.add(Dropout(dropout))
    model.add(Flatten())
    model.add(Dense(50, activation='relu'))
    model.add(Dense(1))
    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')
    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size, verbose=0)
    return model, history

# 游대 Hybrid CNN + LSTM
def train_lstm_cnn_hybrid(X_train, y_train, X_test, y_test, filters=64, kernel_size=2, dropout=0.2, lstm_units=64, learning_rate=0.001, batch_size=32, epochs=50):
    model = Sequential()
    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))
    model.add(MaxPooling1D(pool_size=2))
    model.add(Dropout(dropout))
    model.add(LSTM(lstm_units))
    model.add(Dense(1))
    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')
    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size, verbose=0)
    return model, history

# 游빍 Train all ML models
def train_ml_models(X_train, y_train, X_test, y_test, scaler, all_cols, target_col_log, X_test_seq, y_true_log, inverse_transform_func):
    ml_results = {}
    y_true_real = np.expm1(y_true_log)

    X_train_flat = X_train.reshape(X_train.shape[0], -1)
    X_test_flat = X_test.reshape(X_test.shape[0], -1)

    for name, model in ml_models.items():
        model.fit(X_train_flat, y_train)
        y_pred_scaled = model.predict(X_test_flat)

        y_pred_real_dict = inverse_transform_func(
            y_pred_scaled_dict={name: y_pred_scaled},
            X_test=X_test_seq,
            scaler=scaler,
            target_col_log=target_col_log,
            all_cols=all_cols,
            return_log=False
        )

        y_pred_real = y_pred_real_dict[name]
        metrics = evaluate_model(y_true_real, y_pred_real)
        ml_results[name] = metrics

    return ml_results